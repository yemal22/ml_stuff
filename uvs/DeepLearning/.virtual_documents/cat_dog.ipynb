!pip install h5py # h5py vous permet d'ouvrir les fichiers au format hdf5. N'oubliez pas de l'installer !


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import h5py
# from sklearn.metrics import log_loss


with h5py.File("datasets/trainset.hdf5", "r") as file:
    print(list(file.keys()))


with h5py.File("datasets/trainset.hdf5", "r") as file:
    X_train = file['X_train'][:]
    y_train = file['Y_train'][:]

print(f"X_train:{X_train.shape}")
print(f"y_train:{y_train.shape}")


with h5py.File("datasets/testset.hdf5", "r") as file:
    X_test = file['X_test'][:]
    y_test = file['Y_test'][:]

print(f"X_test:{X_test.shape}")
print(f"y_test:{y_test.shape}")


plt.imshow(X_train[0], cmap='gray_r')


X_train[0].flatten()


def img_to_1d(X):
    row = X.shape[0]
    col = X.shape[1]*X.shape[2]
    X_1d = np.zeros((row, col))
    for i, x in enumerate(X):
        X_1d[i, :] = x.flatten()

    return X_1d


X_train_1d = img_to_1d(X_train)
X_test_1d = img_to_1d(X_test)

print(f"X_train_1d:{X_train_1d.shape}")
print(f"X_test_1d:{X_test_1d.shape}")


from neuron import *


W, b = artificial_neuron(X_train_1d, y_train, learning_rate=1000)


from sklearn.datasets import make_blobs
X, y = make_blobs(n_samples=100, n_features=2, centers=2, random_state=0)

X[:, 1] = X[:, 1]*10
y = y.reshape(-1, 1)
plt.scatter(X[:,0], X[:,1], c=y, cmap='summer')


lim = 10
h = 100
W1 = np.linspace(-lim, lim, h)
W2 = np.linspace(-lim, lim, h)

W11, W22 = np.meshgrid(W1, W2)
W_final = np.c_[W11.ravel(), W22.ravel()].T
W_final.shape


b = 0
Z = X.dot(W_final) + b
A = 1 / (1 + np.exp(-Z))

A.shape

epsilon = 1e-15
L = 1/len(y) * np.sum(-y * np.log(A + epsilon) - (1 - y) * np.log(1 - A + epsilon), axis=0).reshape(100, 100)
L.shape


plt.contourf(W11, W22, L, 10, cmap='magma')
plt.colorbar()



